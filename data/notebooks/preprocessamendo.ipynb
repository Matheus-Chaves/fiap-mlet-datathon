{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "     ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 4.5/13.0 MB 26.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 10.2/13.0 MB 26.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/13.0 MB 25.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 13.0/13.0 MB 21.4 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: syllapy in c:\\users\\miche\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install syllapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "import syllapy\n",
    "from datetime import datetime\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\miche/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\miche/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\miche/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\miche/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\miche/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                      issued                   modified  \\\n",
      "0  2022-06-18 20:37:45+00:00  2023-04-15 00:02:08+00:00   \n",
      "1  2019-06-20 17:19:52+00:00  2023-06-16 20:19:15+00:00   \n",
      "2  2022-07-08 08:55:52+00:00  2023-04-15 04:25:39+00:00   \n",
      "3  2021-09-09 19:06:46+00:00  2023-06-07 17:44:54+00:00   \n",
      "4  2021-09-15 19:16:13+00:00  2023-06-07 17:43:39+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Caso Bruno e Dom: 3¬∫ suspeito tem pris√£o tempo...   \n",
      "1  Linguajar dos santarenos √© diferenciado e chei...   \n",
      "2  Ex-premi√™ Shinzo Abe morre ap√≥s ser baleado no...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  \\nAp√≥s 2 votos, pedido de vista suspende julga...   \n",
      "\n",
      "                                                body  \\\n",
      "0  Ap√≥s audi√™ncia de cust√≥dia, a Justi√ßa do Amazo...   \n",
      "1  Vista a√©rea de Santar√©m\\n√Ådrio Denner/ AD Prod...   \n",
      "2  Novo v√≠deo mostra que assassino de Shinzo Abe ...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  Ap√≥s um pedido de vista (mais tempo para an√°li...   \n",
      "\n",
      "                                             caption  \n",
      "0  Jeferson da Silva Lima foi escoltado por agent...  \n",
      "1  As express√µes santarenas n√£o significam apenas...  \n",
      "2  Ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  Ministro defendeu que posse ind√≠gena √© diferen...  \n",
      "4  Pelo marco temporal, √≠ndios s√≥ podem reivindic...  \n"
     ]
    }
   ],
   "source": [
    "# Lista de arquivos CSV\n",
    "file_paths = [\n",
    "    '../raw/itens/itens-parte1.csv',\n",
    "    '../raw/itens/itens-parte2.csv',\n",
    "    '../raw/itens/itens-parte3.csv'\n",
    "]\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada parte\n",
    "dataframes = []\n",
    "\n",
    "# Loop para carregar cada arquivo CSV e adicion√°-lo √† lista\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um √∫nico\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame combinado\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Caso Bruno e Dom: 3¬∫ suspeito tem pris√£o tempo...   \n",
      "1  Linguajar dos santarenos √© diferenciado e chei...   \n",
      "2  Ex-premi√™ Shinzo Abe morre ap√≥s ser baleado no...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  \\nAp√≥s 2 votos, pedido de vista suspende julga...   \n",
      "\n",
      "                                                body  \\\n",
      "0  Ap√≥s audi√™ncia de cust√≥dia, a Justi√ßa do Amazo...   \n",
      "1  Vista a√©rea de Santar√©m\\n√Ådrio Denner/ AD Prod...   \n",
      "2  Novo v√≠deo mostra que assassino de Shinzo Abe ...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  Ap√≥s um pedido de vista (mais tempo para an√°li...   \n",
      "\n",
      "                                             caption  \n",
      "0  Jeferson da Silva Lima foi escoltado por agent...  \n",
      "1  As express√µes santarenas n√£o significam apenas...  \n",
      "2  Ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  Ministro defendeu que posse ind√≠gena √© diferen...  \n",
      "4  Pelo marco temporal, √≠ndios s√≥ podem reivindic...  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['modified'])\n",
    "\n",
    "# Remover linhas com valores ausentes nas colunas essenciais\n",
    "df = df.dropna(subset=['url', 'title', 'body'])\n",
    "\n",
    "# Convertendo as colunas 'issued' para datetime\n",
    "df['issued'] = pd.to_datetime(df['issued'], errors='coerce')\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas encontradas no DataFrame:\n",
      "- title est√° presente\n",
      "- body est√° presente\n",
      "- caption est√° presente\n"
     ]
    }
   ],
   "source": [
    "# Colunas que ser√£o limpas\n",
    "columns_to_clean = [\"title\", \"body\", \"caption\"]\n",
    "\n",
    "# Verificando se as colunas existem no DataFrame\n",
    "print(\"Colunas encontradas no DataFrame:\")\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        print(f\"- {column} est√° presente\")\n",
    "    else:\n",
    "        print(f\"- {column} N√ÉO est√° presente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_34216\\1292987479.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace('\\n', ' ').replace('\\r', ' ') if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Caso Bruno e Dom: 3¬∫ suspeito tem pris√£o tempo...   \n",
      "1  Linguajar dos santarenos √© diferenciado e chei...   \n",
      "2  Ex-premi√™ Shinzo Abe morre ap√≥s ser baleado no...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4   Ap√≥s 2 votos, pedido de vista suspende julgam...   \n",
      "\n",
      "                                                body  \\\n",
      "0  Ap√≥s audi√™ncia de cust√≥dia, a Justi√ßa do Amazo...   \n",
      "1  Vista a√©rea de Santar√©m √Ådrio Denner/ AD Produ...   \n",
      "2  Novo v√≠deo mostra que assassino de Shinzo Abe ...   \n",
      "3  Relator no STF, Fachin vota contra marco tempo...   \n",
      "4  Ap√≥s um pedido de vista (mais tempo para an√°li...   \n",
      "\n",
      "                                             caption  \n",
      "0  Jeferson da Silva Lima foi escoltado por agent...  \n",
      "1  As express√µes santarenas n√£o significam apenas...  \n",
      "2  Ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  Ministro defendeu que posse ind√≠gena √© diferen...  \n",
      "4  Pelo marco temporal, √≠ndios s√≥ podem reivindic...  \n"
     ]
    }
   ],
   "source": [
    "df = df.applymap(lambda x: x.replace('\\n', ' ').replace('\\r', ' ') if isinstance(x, str) else x)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto transformado para min√∫sculas:\n",
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  caso bruno e dom: 3¬∫ suspeito tem pris√£o tempo...   \n",
      "1  linguajar dos santarenos √© diferenciado e chei...   \n",
      "2  ex-premi√™ shinzo abe morre ap√≥s ser baleado no...   \n",
      "3  relator no stf, fachin vota contra marco tempo...   \n",
      "4   ap√≥s 2 votos, pedido de vista suspende julgam...   \n",
      "\n",
      "                                                body  \\\n",
      "0  ap√≥s audi√™ncia de cust√≥dia, a justi√ßa do amazo...   \n",
      "1  vista a√©rea de santar√©m √°drio denner/ ad produ...   \n",
      "2  novo v√≠deo mostra que assassino de shinzo abe ...   \n",
      "3  relator no stf, fachin vota contra marco tempo...   \n",
      "4  ap√≥s um pedido de vista (mais tempo para an√°li...   \n",
      "\n",
      "                                             caption  \n",
      "0  jeferson da silva lima foi escoltado por agent...  \n",
      "1  as express√µes santarenas n√£o significam apenas...  \n",
      "2  ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  ministro defendeu que posse ind√≠gena √© diferen...  \n",
      "4  pelo marco temporal, √≠ndios s√≥ podem reivindic...  \n"
     ]
    }
   ],
   "source": [
    "# Transformando os textos em min√∫sculas\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].str.lower()\n",
    "\n",
    "# Exibindo as primeiras linhas ap√≥s a transforma√ß√£o\n",
    "print(\"Texto transformado para min√∫sculas:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  caso bruno e dom: 3o suspeito tem pris√£o tempo...   \n",
      "1  linguajar dos santarenos √© diferenciado e chei...   \n",
      "2  ex-premi√™ shinzo abe morre ap√≥s ser baleado no...   \n",
      "3  relator no stf, fachin vota contra marco tempo...   \n",
      "4   ap√≥s 2 votos, pedido de vista suspende julgam...   \n",
      "5  o que √© o marco temporal sobre terras ind√≠gena...   \n",
      "6  shannen doherty, de 'barrados no baile', compa...   \n",
      "7  como cornershop criou hit 'complicado' com mis...   \n",
      "8                                       equipe do g1   \n",
      "9  terceiro suspeito de participar dos assassinat...   \n",
      "\n",
      "                                                body  \\\n",
      "0  ap√≥s audi√™ncia de cust√≥dia, a justi√ßa do amazo...   \n",
      "1  vista a√©rea de santar√©m √°drio denner/ ad produ...   \n",
      "2  novo v√≠deo mostra que assassino de shinzo abe ...   \n",
      "3  relator no stf, fachin vota contra marco tempo...   \n",
      "4  ap√≥s um pedido de vista (mais tempo para an√°li...   \n",
      "5  marco temporal sobre terras ind√≠genas: entenda...   \n",
      "6  shannen doherty, de 'barrados no baile', compa...   \n",
      "7  quando eu hitei: cornershop teve hit 'complica...   \n",
      "8  conhe√ßa a equipe completa:  diretor-geral de j...   \n",
      "9  terceiro suspeito de participar dos assassinat...   \n",
      "\n",
      "                                             caption  \n",
      "0  jeferson da silva lima foi escoltado por agent...  \n",
      "1  as express√µes santarenas n√£o significam apenas...  \n",
      "2  ex-primeiro-ministro foi atingido por tiros de...  \n",
      "3  ministro defendeu que posse ind√≠gena √© diferen...  \n",
      "4  pelo marco temporal, √≠ndios s√≥ podem reivindic...  \n",
      "5  tese analisada pelo supremo ap√≥s recurso da fu...  \n",
      "6  nas redes sociais, atriz afirmou que usou 'o h...  \n",
      "7  ao g1, vocalista relembra 30 anos da banda de ...  \n",
      "8  conhe√ßa a equipe completa de pessoas respons√°v...  \n",
      "9  a justi√ßa determinou que o pescador jefferson ...  \n"
     ]
    }
   ],
   "source": [
    "def normalize_unicode(text):\n",
    "    if isinstance(text, str):\n",
    "        return unicodedata.normalize(\"NFKC\", text)  # Normaliza caracteres Unicode\n",
    "    return text\n",
    "\n",
    "# Aplicando normaliza√ß√£o Unicode antes da remo√ß√£o de acentos\n",
    "for column in [\"title\", \"body\", \"caption\"]:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(normalize_unicode)  # Normalizar caracteres Unicode\n",
    "\n",
    "# Exibir os dados ap√≥s a limpeza\n",
    "print(df[[\"title\", \"body\", \"caption\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  caso bruno e dom o suspeito tem priso temporri...   \n",
      "1  linguajar dos santarenos diferenciado e cheio ...   \n",
      "2  ex premi shinzo abe morre aps ser baleado no japo   \n",
      "3  relator no stf fachin vota contra marco tempor...   \n",
      "4  aps votos pedido de vista suspende julgamento ...   \n",
      "\n",
      "                                                body  \\\n",
      "0  aps audincia de custdia a justia do amazonas d...   \n",
      "1  vista area de santarm drio denner ad produes o...   \n",
      "2  novo vdeo mostra que assassino de shinzo abe a...   \n",
      "3  relator no stf fachin vota contra marco tempor...   \n",
      "4  aps um pedido de vista mais tempo para anlise ...   \n",
      "\n",
      "                                             caption  \n",
      "0  jeferson da silva lima foi escoltado por agent...  \n",
      "1  as expresses santarenas no significam apenas o...  \n",
      "2  ex primeiro ministro foi atingido por tiros de...  \n",
      "3  ministro defendeu que posse indgena diferente ...  \n",
      "4  pelo marco temporal ndios s podem reivindicar ...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# üîπ Fun√ß√£o para remover caracteres de escape como \"\\r\" e \"\\n\"\n",
    "def remove_escape_chars(text):\n",
    "    return text.replace(\"\\r\", \" \").replace(\"\\n\", \" \") if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover express√µes regulares espec√≠ficas\n",
    "def remove_regex_patterns(text, patterns):\n",
    "    if isinstance(text, str):\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover n√∫meros\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover pontua√ß√£o\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation)) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover espa√ßos extras\n",
    "def remove_extra_spaces(text):\n",
    "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para substituir h√≠fens por espa√ßos\n",
    "def replace_hyphens(text):\n",
    "    return re.sub(r'(?<=\\w)-(?=\\w)', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover colchetes e seu conte√∫do\n",
    "def remove_brackets(text):\n",
    "    return re.sub(r'\\[.*?\\]', '', text) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover palavras vazias\n",
    "def remove_empty_words(text):\n",
    "    return ' '.join([word for word in text.split() if word != '']) if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Fun√ß√£o para remover underscores\n",
    "def remove_underscores(text):\n",
    "    return text.replace(\"_\", \"\") if isinstance(text, str) else text\n",
    "\n",
    "# üîπ Padr√µes regex a serem removidos\n",
    "regex_patterns = [\n",
    "    r\"http\\S+\",   # URLs\n",
    "    r\"@\\w+\",      # Men√ß√µes\n",
    "    r\"#\\w+\",      # Hashtags\n",
    "    r\"¬∫\",         # Caractere ¬∫\n",
    "    r\"[^a-zA-Z0-9\\s]\",  # Outros caracteres especiais (exceto espa√ßos)\n",
    "]\n",
    "\n",
    "# Aplicando as fun√ß√µes de pr√©-processamento nas colunas\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(remove_escape_chars)    # Remover caracteres como \\r e \\n\n",
    "        df[column] = df[column].apply(replace_hyphens)        # Substituir h√≠fens por espa√ßos\n",
    "        df[column] = df[column].apply(lambda x: remove_regex_patterns(x, regex_patterns))  # Remover padr√µes regex\n",
    "        df[column] = df[column].apply(remove_numbers)         # Remover n√∫meros\n",
    "        df[column] = df[column].apply(remove_punctuation)     # Remover pontua√ß√£o\n",
    "        df[column] = df[column].apply(remove_extra_spaces)    # Remover espa√ßos extras\n",
    "        df[column] = df[column].apply(remove_brackets)        # Remover colchetes\n",
    "        df[column] = df[column].apply(remove_empty_words)     # Remover palavras vazias\n",
    "        df[column] = df[column].apply(remove_underscores)     # Remover underscores\n",
    "\n",
    "# Exibir as primeiras linhas ap√≥s o pr√©-processamento\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  caso bruno e dom o suspeito tem priso temporri...   \n",
      "1  linguajar dos santarenos diferenciado e cheio ...   \n",
      "2  ex premi shinzo abe morre aps ser baleado no japo   \n",
      "3  relator no stf fachin vota contra marco tempor...   \n",
      "4  aps votos pedido de vista suspende julgamento ...   \n",
      "\n",
      "                                                body  \\\n",
      "0  aps audincia de custdia a justia do amazonas d...   \n",
      "1  vista area de santarm drio denner ad produes o...   \n",
      "2  novo vdeo mostra que assassino de shinzo abe a...   \n",
      "3  relator no stf fachin vota contra marco tempor...   \n",
      "4  aps um pedido de vista mais tempo para anlise ...   \n",
      "\n",
      "                                             caption  \n",
      "0  jeferson da silva lima foi escoltado por agent...  \n",
      "1  as expresses santarenas no significam apenas o...  \n",
      "2  ex primeiro ministro foi atingido por tiros de...  \n",
      "3  ministro defendeu que posse indgena diferente ...  \n",
      "4  pelo marco temporal ndios s podem reivindicar ...  \n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para remover emojis\n",
    "def remove_emojis(text):\n",
    "    \"\"\"\n",
    "    Remove emojis de um texto utilizando express√µes regulares.\n",
    "    :param text: Texto de entrada.\n",
    "    :return: Texto sem emojis.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Verifica se o valor √© uma string\n",
    "        emoji_pattern = re.compile(\n",
    "            \"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # S√≠mbolos e pictogramas\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # Transportes e s√≠mbolos adicionais\n",
    "            \"\\U0001F1E0-\\U0001F1FF\"  # Bandeiras (sub-regi√µes)\n",
    "            \"\\U00002500-\\U00002BEF\"  # Outros s√≠mbolos\n",
    "            \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "            \"\\U0001F900-\\U0001F9FF\"  # Suplementos de emojis\n",
    "            \"\\U0001FA70-\\U0001FAFF\"  # Suplementos adicionais\n",
    "            \"\\U00002600-\\U000026FF\"  # Diversos s√≠mbolos (como ‚ô™)\n",
    "            \"\\U0001F000-\\U0001F02F\"  # Cartas de jogo\n",
    "            \"]+\",\n",
    "            flags=re.UNICODE,\n",
    "        )\n",
    "        return emoji_pattern.sub(r\"\", text)  # Remove emojis\n",
    "    return text  # Retorna o valor original se n√£o for uma string\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(remove_emojis)\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para tokenizar o texto\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)  # Retorna uma lista de tokens\n",
    "\n",
    "# Fun√ß√£o para remover stopwords de uma lista de tokens\n",
    "def remove_stopwords(tokens, language='portuguese'):\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    return [word for word in tokens if word.lower() not in stop_words]  # Remove stopwords e converte para min√∫sculas\n",
    "\n",
    "# Aplicando as fun√ß√µes no DataFrame corretamente\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(lambda x: remove_stopwords(tokenize_text(str(x))))\n",
    "# Exibir as primeiras linhas do DataFrame ap√≥s a limpeza\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  caso bruno dom suspeito prisao temporar decret...   \n",
      "1  linguajar santareno diferenciar cheio identida...   \n",
      "2       ex premie shinzo abe morrer apo balear Japao   \n",
      "3  relator stf fachin vota marco temporal demarca...   \n",
      "4  apo voto pedir vista suspender julgamento stf ...   \n",
      "\n",
      "                                                body  \\\n",
      "0  apo audiencia custodio justico amazona decreta...   \n",
      "1  ver aereo santar adrio Denner ad producoes par...   \n",
      "2  video mostrar assassino shinzo abe atirar cost...   \n",
      "3  relator stf fachin vota marco temporal demarca...   \n",
      "4  apo pedir vista analise processo ministro Alex...   \n",
      "\n",
      "                                             caption  \n",
      "0  Jeferson Silva lima escoltar agente policia fe...  \n",
      "1  expressoe santareno nao significar nao signifi...  \n",
      "2  ex ministro atingir tiro espingardo caseira di...  \n",
      "3  ministro defender posse indigeno diferente pos...  \n",
      "4  marco temporal indio so reivindicar demarcacao...  \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Fun√ß√£o para lematizar texto com POS usando Spacy\n",
    "def lemmatize_tokens(text):\n",
    "    # Processar o texto com Spacy para an√°lise\n",
    "    doc = nlp(text)  # O Spacy processa a string diretamente\n",
    "\n",
    "    # Lematizando com base no POS e removendo as stopwords\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "    # Retornar os tokens lematizados como uma string\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Aplicando a fun√ß√£o em cada uma das colunas de texto\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        # Garantir que o texto seja passado como string para a fun√ß√£o de lematiza√ß√£o\n",
    "        df[column] = df[column].apply(lambda x: lemmatize_tokens(' '.join(x)))\n",
    "\n",
    "# Exibir as primeiras linhas ap√≥s o pr√©-processamento\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   page  \\\n",
      "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
      "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
      "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
      "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
      "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://g1.globo.com/am/amazonas/noticia/2022/0...   \n",
      "1  http://g1.globo.com/pa/santarem-regiao/noticia...   \n",
      "2  http://g1.globo.com/mundo/noticia/2022/07/08/e...   \n",
      "3  http://g1.globo.com/politica/noticia/2021/09/0...   \n",
      "4  http://g1.globo.com/politica/noticia/2021/09/1...   \n",
      "\n",
      "                     issued  \\\n",
      "0 2022-06-18 20:37:45+00:00   \n",
      "1 2019-06-20 17:19:52+00:00   \n",
      "2 2022-07-08 08:55:52+00:00   \n",
      "3 2021-09-09 19:06:46+00:00   \n",
      "4 2021-09-15 19:16:13+00:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  caso bruno dom suspeito prisao temporar decret...   \n",
      "1  linguajar santareno diferenciar cheio identida...   \n",
      "2             ex premie shinzo abe morrer apo balear   \n",
      "3  relator stf fachin vota marco temporal demarca...   \n",
      "4  apo voto pedir vista suspender julgamento stf ...   \n",
      "\n",
      "                                                body  \\\n",
      "0  apo audiencia custodio justico amazona decreta...   \n",
      "1  ver aereo santar adrio ad producoes paraense v...   \n",
      "2  video mostrar assassino shinzo abe atirar cost...   \n",
      "3  relator stf fachin vota marco temporal demarca...   \n",
      "4  apo pedir vista analise processo ministro mora...   \n",
      "\n",
      "                                             caption  \n",
      "0  lima escoltar agente policia federal forum jus...  \n",
      "1  expressoe santareno nao significar nao signifi...  \n",
      "2  ex ministro atingir caseira discursar campanha...  \n",
      "3  ministro defender posse indigeno diferente pos...  \n",
      "4  terro ja ocupar data constituicao nunes marque...  \n"
     ]
    }
   ],
   "source": [
    "def remove_person_names(text):\n",
    "    # Processar o texto com Spacy para an√°lise\n",
    "    doc = nlp(text)\n",
    "    # Criar uma lista com os tokens que n√£o s√£o entidades do tipo \"pessoa\"\n",
    "    cleaned_text = [token.text for token in doc if token.ent_type_ != 'PER']\n",
    "\n",
    "    # Unir os tokens novamente em uma string\n",
    "    return ' '.join(cleaned_text)\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(lambda x: remove_person_names(x))\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame ap√≥s a limpeza\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page   url issued title  body caption\n",
      "0  None  None   None  None  None    None\n",
      "1  None  None   None  None  None    None\n",
      "2  None  None   None  None  None    None\n",
      "3  None  None   None  None  None    None\n",
      "4  None  None   None  None  None    None\n"
     ]
    }
   ],
   "source": [
    "# Lista de palavras que voc√™ deseja manter, como \"ex\"\n",
    "words_to_keep = {\"ex\"}\n",
    "\n",
    "# Fun√ß√£o para contar s√≠labas usando syllapy\n",
    "def count_syllables(word):\n",
    "    # Contar s√≠labas com a biblioteca syllapy\n",
    "    return syllapy.count(word)\n",
    "\n",
    "# Fun√ß√£o para remover palavras de duas s√≠labas e de uma letra, mantendo palavras espec√≠ficas\n",
    "def remove_two_syllables(text):\n",
    "    words = word_tokenize(text)  # Tokenizar o texto\n",
    "    filtered_words = [\n",
    "        word for word in words\n",
    "        if len(word) > 1 and count_syllables(word) != 2 or word.lower() in words_to_keep  # Verifica palavras com 2 s√≠labas e palavras com 1 letra\n",
    "    ]\n",
    "    return \" \".join(filtered_words)  # Retorna o texto ap√≥s a remo√ß√£o\n",
    "\n",
    "for column in df.columns:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].apply(lambda x: process_text(str(x)))  # Aplica a fun√ß√£o nas c√©lulas da coluna\n",
    "\n",
    "# Exibir as primeiras linhas ap√≥s a aplica√ß√£o\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Salvar o DataFrame processado em um arquivo CSV\n",
    "df.to_csv('../preprocessed/itens/dados_preprocessados.csv', index=False)\n",
    "\n",
    "print(\"Arquivo CSV salvo com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
